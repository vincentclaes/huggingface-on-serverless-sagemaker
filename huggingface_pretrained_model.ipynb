{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Huggingface Model to Serverless Sagemaker\n",
    "\n",
    "- set the kernel to a pytorch kernel\n",
    "- load a model from huggingface hub\n",
    "- register the model\n",
    "\n",
    "### Links\n",
    "\n",
    "- https://huggingface.co/docs/sagemaker/inference#deploy-a-model-from-the-hub\n",
    "- https://www.youtube.com/watch?v=l9QZuazbzWM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Sagemaker SDK\n",
    "#### 1.1 Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english', # model_id from hf.co/models\n",
    "  'HF_TASK':'sentiment-analysis'                           # NLP task you want to use for predictions\n",
    "}\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,                                                # configuration for loading model from Hub\n",
    "   role=role,                                              # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                             # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                  # PyTorch version used\n",
    "   py_version='py36',                                      # Python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Deploy a Model and call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serverless_inference_config={\n",
    "        \"MemorySizeInMB\":1024,\n",
    "        \"MaxConcurrency\":10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.67 ms, sys: 3.47 ms, total: 12.1 ms\n",
      "Wall time: 166 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998599290847778}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = {\n",
    "   \"inputs\": \"I really like this place!\"\n",
    "}\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Remove the serverless sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker delete-endpoint --endpoint-name $predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huggingface on Serverless Sagemaker deployed by Serverless.com\n",
    "\n",
    "- Using sagemaker sdk you can deploy an endpoint, but you can only reach a sagemaker endpoint from within an AWS account.\n",
    "- Typically you want to expose your model to the outside world, another network\n",
    "- You want to deploy yoouor models from IAC.\n",
    "\n",
    "#### 2.1 create a sagemaker moodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sagemaker model\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/d635faff4ac54f80465f7bc7f3181f67336e249a/src/sagemaker/model.py#L261\n",
    "# Maybe not the best way to create a sagemaker model, but i didn't found a better way.\n",
    "\n",
    "huggingface_model._create_sagemaker_model(instance_type=\"ml.m5.xlarge\", accelerator_type=None, tags=None)\n",
    "sagemaker_model_name = huggingface_model.name\n",
    "sagemaker_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 create a lambda to call the sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_handler.py\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\")\n",
    "sagemaker_endpoint_name = os.environ[\"SAGEMAKER_ENDPOINT_NAME\"]\n",
    "\n",
    "def handler(event, context):\n",
    "\n",
    "    data = json.loads(event[\"body\"])[\"data\"]\n",
    "    print(f\"making a prediction on the text: {data}\")\n",
    "    \n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        Body=json.dumps(data),\n",
    "        EndpointName=sagemaker_endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    \n",
    "    print(f\"prediction: {response}\")\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(prediction)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 create a serverless.yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to write variables to a textfile\n",
    "# https://github.com/ipython/ipython/issues/6701#issuecomment-382640776\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate serverless.yml\n",
    "service: huggingface-on-serverless-sagemaker\n",
    "\n",
    "provider:\n",
    "  name: aws\n",
    "  region: eu-west-1 \n",
    "\n",
    "functions:\n",
    "  huggingface:\n",
    "    handler: lambda_handler.py\n",
    "    timeout: 120\n",
    "    provisionedConcurrency: 1\n",
    "    memorySize: 128 \n",
    "    events:\n",
    "      - http:\n",
    "          path: prediction\n",
    "          method: post\n",
    "    environment:\n",
    "      SAGEMAKER_ENDPOINT_NAME: !GetAtt SageMakerEndpoint.EndpointName\n",
    "\n",
    "resources:\n",
    "  Resources:\n",
    "    SageMakerEndpointConfig:\n",
    "      Type: AWS::SageMaker::EndpointConfig\n",
    "      Properties:\n",
    "        ProductionVariants:\n",
    "          - ModelName: {sagemaker_model_name}\n",
    "            VariantName: SageMakerModel\n",
    "            ServerlessConfig:\n",
    "              MaxConcurrency: 1\n",
    "              MemorySizeInMB: 1024\n",
    "\n",
    "    SageMakerEndpoint:\n",
    "      Type: AWS::SageMaker::Endpoint\n",
    "      Properties:\n",
    "        EndpointConfigName: !GetAtt SageMakerEndpointConfig.EndpointConfigName\n",
    "        EndpointName: huggingface-serverless-sagemaker-endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SageMaker Model Package cannot be created without model data.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2a525bdc0b41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhuggingface_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ml.m5.xlarge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ml.m5.xlarge\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/huggingface/model.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, content_types, response_types, inference_instances, transform_instances, model_package_name, model_package_group_name, image_uri, model_metrics, metadata_properties, marketplace_cert, approval_status, description, drift_check_baselines)\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mapproval_status\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mdrift_check_baselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrift_check_baselines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         )\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, content_types, response_types, inference_instances, transform_instances, model_package_name, model_package_group_name, image_uri, model_metrics, metadata_properties, marketplace_cert, approval_status, description, drift_check_baselines)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelPackage\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \"\"\"\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SageMaker Model Package cannot be created without model data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage_uri\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: SageMaker Model Package cannot be created without model data."
     ]
    }
   ],
   "source": [
    "# huggingface_model.register(content_types=[\"application/json\"], response_types=[\"application/json\"], inference_instances=[\"ml.m5.xlarge\"], transform_instances=[\"ml.m5.xlarge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-inference-2022-01-30-13-16-40-093\n"
     ]
    }
   ],
   "source": [
    "#  huggingface_model._create_sagemaker_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Image': '763104351884.dkr.ecr.eu-west-1.amazonaws.com/huggingface-pytorch-inference:1.8.1-transformers4.6-cpu-py36-ubuntu18.04',\n",
       " 'Environment': {'HF_MODEL_ID': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
       "  'HF_TASK': 'sentiment-analysis',\n",
       "  'SAGEMAKER_PROGRAM': '',\n",
       "  'SAGEMAKER_SUBMIT_DIRECTORY': '',\n",
       "  'SAGEMAKER_CONTAINER_LOG_LEVEL': '20',\n",
       "  'SAGEMAKER_REGION': 'eu-west-1'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  huggingface_model.prepare_container_def()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
