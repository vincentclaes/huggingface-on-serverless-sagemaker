{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Huggingface Model to Serverless Sagemaker\n",
    "\n",
    "- set the kernel to a pytorch kernel\n",
    "- load a model from huggingface hub\n",
    "- register the model\n",
    "\n",
    "### Links\n",
    "\n",
    "- https://huggingface.co/docs/sagemaker/inference#deploy-a-model-from-the-hub\n",
    "- https://www.youtube.com/watch?v=l9QZuazbzWM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sagemaker --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.huggingface.model import HuggingFaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using Sagemaker SDK\n",
    "#### 1.1 Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub model configuration <https://huggingface.co/models>\n",
    "hub = {\n",
    "  'HF_MODEL_ID':'distilbert-base-uncased-finetuned-sst-2-english', # model_id from hf.co/models\n",
    "  'HF_TASK':'sentiment-analysis'                           # NLP task you want to use for predictions\n",
    "}\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   env=hub,                                                # configuration for loading model from Hub\n",
    "   role=role,                                              # IAM role with permissions to create an endpoint\n",
    "   transformers_version=\"4.6\",                             # Transformers version used\n",
    "   pytorch_version=\"1.7\",                                  # PyTorch version used\n",
    "   py_version='py36',                                      # Python version used\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Deploy a Model and call it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serverless_inference_config={\n",
    "        \"MemorySizeInMB\":1024,\n",
    "        \"MaxConcurrency\":10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.53 ms, sys: 10.6 ms, total: 18.1 ms\n",
      "Wall time: 113 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998599290847778}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = {\n",
    "   \"inputs\": \"I really like this place!\"\n",
    "}\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Remove the serverless sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker delete-endpoint --endpoint-name $predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Huggingface on Serverless Sagemaker deployed by Serverless.com\n",
    "\n",
    "- Using sagemaker sdk you can deploy an endpoint, but you can only reach a sagemaker endpoint from within an AWS account.\n",
    "- Typically you want to expose your model to the outside world, another network\n",
    "- You want to deploy yoouor models from IAC.\n",
    "\n",
    "#### 2.1 create a sagemaker moodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sagemaker model\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/d635faff4ac54f80465f7bc7f3181f67336e249a/src/sagemaker/model.py#L261\n",
    "# Maybe not the best way to create a sagemaker model, but i didn't found a better way.\n",
    "\n",
    "huggingface_model._create_sagemaker_model(instance_type=\"ml.m5.xlarge\", accelerator_type=None, tags=None)\n",
    "sagemaker_model_name = huggingface_model.name\n",
    "sagemaker_model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 create a lambda to call the sagemaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lambda_handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lambda_handler.py\n",
    "import json\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "runtime_client = boto3.client(\"runtime.sagemaker\")\n",
    "sagemaker_endpoint_name = os.environ[\"SAGEMAKER_ENDPOINT_NAME\"]\n",
    "\n",
    "def handler(event, context):\n",
    "\n",
    "    print(f\"making a prediction on the text: {event['body']}\")\n",
    "    \n",
    "    response = runtime_client.invoke_endpoint(\n",
    "        Body=event[\"body\"],\n",
    "        EndpointName=sagemaker_endpoint_name,\n",
    "        Accept=\"application/json\",\n",
    "        ContentType=\"application/json\",\n",
    "    )\n",
    "    \n",
    "    print(f\"prediction: {response}\")\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(prediction)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 create a serverless.yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to write variables to a textfile\n",
    "# https://github.com/ipython/ipython/issues/6701#issuecomment-382640776\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate serverless.yml\n",
    "service: huggingface-on-serverless-sagemaker\n",
    "\n",
    "provider:\n",
    "  name: aws\n",
    "  region: eu-west-1 \n",
    "  runtime: python3.8\n",
    "  iam:\n",
    "    role:\n",
    "      managedPolicies: arn:aws:iam::aws:policy/AdministratorAccess\n",
    "\n",
    "\n",
    "functions:\n",
    "  huggingface:\n",
    "    handler: lambda_handler.handler\n",
    "    timeout: 120\n",
    "    memorySize: 128 \n",
    "    events:\n",
    "      - http:\n",
    "          path: prediction\n",
    "          method: post\n",
    "    environment:\n",
    "      SAGEMAKER_ENDPOINT_NAME: !GetAtt SageMakerEndpoint.EndpointName\n",
    "\n",
    "resources:\n",
    "  Resources:\n",
    "    SageMakerEndpointConfig:\n",
    "      Type: AWS::SageMaker::EndpointConfig\n",
    "      Properties:\n",
    "        ProductionVariants:\n",
    "          - ModelName: {sagemaker_model_name}\n",
    "            InitialVariantWeight: 1.0\n",
    "            VariantName: SageMakerModel\n",
    "            ServerlessConfig:\n",
    "              MaxConcurrency: 1\n",
    "              MemorySizeInMB: 1024\n",
    "\n",
    "    SageMakerEndpoint:\n",
    "      Type: AWS::SageMaker::Endpoint\n",
    "      Properties:\n",
    "        EndpointConfigName: !GetAtt SageMakerEndpointConfig.EndpointConfigName\n",
    "        EndpointName: huggingface-serverless-sagemaker-endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 open an AWS cloud shell and deploy the application\n",
    "\n",
    "```\n",
    "git clone https://github.com/vincentclaes/huggingface-on-serverless-sagemaker.git\n",
    "\n",
    "cd huggingface-on-serverless-sagemaker/\n",
    "\n",
    "npm install serverless\n",
    "\n",
    "/home/cloudshell-user/node_modules/serverless/bin/serverless.js deploy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Call the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Endpoint request timed out\"}CPU times: user 451 ms, sys: 96.2 ms, total: 547 ms\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!curl -d '{\"inputs\":\"some very much wow positive text!\"}' -H \"Content-Type: application/json\" -X POST  https://2kqraqs038.execute-api.eu-west-1.amazonaws.com/dev/prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 remove the stack\n",
    "\n",
    "```\n",
    "/home/cloudshell-user/node_modules/serverless/bin/serverless.js remove\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.8 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/1.8.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
